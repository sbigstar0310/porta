# app.py
from graph.root_graph import build_root_graph
import os
from graph.schemas import ParentState
from datetime import datetime
from data.schemas import PortfolioOut
from graph.llm_clients.openai_client import get_openai_client
import logging
import time
from langchain_core.runnables.config import RunnableConfig

logger = logging.getLogger(__name__)


def activate_langsmith():
    os.environ["LANGCHAIN_TRACING_V2"] = "true"
    os.environ["LANGCHAIN_PROJECT"] = "porta"


def run_graph(portfolio: PortfolioOut, user_id: int, language: str = "ko", debug: bool = True) -> dict:
    """
    Porta Agent Pipeline ì‹¤í–‰

    Args:
        portfolio: PortfolioOut
        user_id: int
        language: ì–¸ì–´ ì„¤ì •
        debug: ë””ë²„ê·¸ ëª¨ë“œ (Trueì‹œ ìƒì„¸ ë¡œê·¸ ì¶œë ¥)

    Returns:
        dict: íŒŒì´í”„ë¼ì¸ ê²°ê³¼
    """

    if debug:
        logger.info("ğŸš€ Porta Agent Pipeline ì‹œì‘ (ë””ë²„ê·¸ ëª¨ë“œ)")
        logger.info(f"ğŸ“Š í¬íŠ¸í´ë¦¬ì˜¤: {len(portfolio.positions)}ê°œ ì¢…ëª©")
        start_time = time.time()

    # activate langsmith
    activate_langsmith()

    # llm client
    light_llm_client = get_openai_client(model_name="gpt-5-mini")
    middle_llm_client = get_openai_client(model_name="gpt-5")
    heavy_llm_client = get_openai_client(model_name="gpt-5")
    base_llm_client = get_openai_client(model_name="gpt-5-nano")

    if debug:
        logger.info("ğŸ¤– LLM í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")

    # build root graph
    app = build_root_graph(
        light_llm_client=light_llm_client,
        middle_llm_client=middle_llm_client,
        heavy_llm_client=heavy_llm_client,
        base_llm_client=base_llm_client,
    )

    if debug:
        logger.info("ğŸ“Š ê·¸ë˜í”„ ë¹Œë“œ ì™„ë£Œ")

    # initial state
    initial_state: ParentState = ParentState(
        messages=[],
        portfolio=portfolio.model_dump(),
        asof=datetime.utcnow().isoformat(),
        universe=[pos.ticker for pos in portfolio.positions],
        user_id=user_id,
        language=language,
    )

    if debug:
        logger.info("ğŸ¯ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹œì‘")

    # invoke pipeline with user_id in config
    config = RunnableConfig(recursion_limit=30, configurable={"user_id": user_id})
    result = app.invoke(initial_state, config=config)

    if debug:
        end_time = time.time()
        logger.info(f"âœ… íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì™„ë£Œ (ì†Œìš”ì‹œê°„: {end_time - start_time:.2f}ì´ˆ)")
        logger.info(f"ğŸ“‹ ê²°ê³¼ í‚¤: {list(result.keys())}")

    return result
